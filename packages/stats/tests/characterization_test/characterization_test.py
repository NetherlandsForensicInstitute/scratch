import csv
from collections import defaultdict
from pathlib import Path

import pytest
from lrmodule.data_types import LLR_data
from lrmodule.determine_lr import scores_to_llrs


def _parse_csv_input_file(input_file_path: Path) -> dict[str, list]:
    """Parse input data into dictionary which keys represent data type.

    Typically, a dictionary with the following keys is generated, due to
    the nature of the data, containing evaluation scores, known match scores
    and known non match scores.
    {
        "eval": [],
        "km": [],
        "knm": [],
    }
    """
    groups = defaultdict(list)

    with open(input_file_path) as f:
        reader = csv.reader(f)

        for type_, value in reader:
            groups[type_].append(value)

    return groups


def parse_expected_output(expected_output_file_path: Path) -> list[LLR_data]:
    """Extract expected LLR data from the output file generated by Matlab code.

    The output file holds 5%-percentile, best estimate/median and 95%-percentile
    LLR values.

    The function provides a list of tuples, each tuple represents the 5%-percentile,
    best estimate/median and 95%-percentile LLR value.
    """
    # Keep a collection of LLR_data tuples in a list, which is returned at the end
    expected_llrs: list[LLR_data | None] = []

    with open(expected_output_file_path) as f:
        reader = csv.reader(f)

        for row in reader:
            expected_llrs.append(
                LLR_data(
                    low_percentile=float(row[0]),
                    best_estimate=float(row[1]),
                    high_percentile=float(row[2]),
                )
            )

    return expected_llrs


@pytest.mark.parametrize(
    "csv_file_name",
    [
        "aperture_shear-ccf-subset.csv",
    ],
)
def test_characterization_test_input_output_files(csv_file_name: str):
    """Check that for a given input, the expected output is provided."""
    # Given the input scores from a specific CSV
    input_data = _parse_csv_input_file(Path(__file__).parent / "score_input" / csv_file_name)
    evaluation_scores = input_data["eval"]
    known_match_scores = input_data["km"]
    known_non_match_scores = input_data["knm"]

    # When we use this data to obtain LLRS
    calculated_llrs = scores_to_llrs(evaluation_scores, known_match_scores, known_non_match_scores)

    # These should match the expected LLR values
    expected_llrs = parse_expected_output(Path(__file__).parent / "expected_llr_output" / csv_file_name)

    # # Pickle dump the expected LLRs for later re-use (temporary)
    # with open(Path(__file__).parent / 'expected_aperture_shear_LLRS.pkl', 'wb') as f:
    #     pickle.dump(expected_llrs, f)

    assert calculated_llrs == expected_llrs
